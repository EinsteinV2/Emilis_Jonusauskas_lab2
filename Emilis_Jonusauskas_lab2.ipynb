{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Susikeliam naudojamus paketus"
      ],
      "metadata": {
        "id": "LhYyF9v2PPRB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bAnG9LsCl3Ce"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle, gzip\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from google.colab import files\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4Ydgx5Sp8D8"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDaKF_x23ReP",
        "outputId": "a9c23c70-e3a6-42d6-a2f1-393ce676675a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Susitvarkome duomenų formatą. Taip pat atliekame kelias posūkio, vertimo, spalvos ir padidinimo transformacijas turimiems duomenims ir pridedame prie esamų"
      ],
      "metadata": {
        "id": "6WFW65GrOQWQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngR8aj-Jkg0K",
        "outputId": "bf215e6f-548f-44cd-eaf2-d6dd2f33bf02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Training data shape: torch.Size([14000, 1, 50, 50])\n",
            "New Training data shape: torch.Size([3000, 1, 50, 50])\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "with gzip.open('/content/drive/MyDrive/Colab Notebooks/flatland_train.data', 'rb') as f:\n",
        "    X, y = pickle.load(f)\n",
        "\n",
        "X = X / 255.0\n",
        "\n",
        "X = X.reshape(-1, 1, 50, 50)\n",
        "\n",
        "\n",
        "y[y != 0] -= 2\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "class ShapeDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "    def shape(self):\n",
        "        return torch.Size([len(self.images)] + list(self.images[0].shape))\n",
        "\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "\n",
        "augmentation_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=1),\n",
        "    transforms.RandomVerticalFlip(p=1),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3)\n",
        "])\n",
        "\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    original_image = X_train[i]\n",
        "    label = y_train[i]\n",
        "\n",
        "    augmented_images.append(original_image)\n",
        "    augmented_labels.append(label)\n",
        "\n",
        "    transformed_image = augmentation_transforms(transforms.ToPILImage()(original_image))\n",
        "    transformed_image = transforms.ToTensor()(transformed_image)\n",
        "\n",
        "    augmented_images.append(transformed_image)\n",
        "    augmented_labels.append(label)\n",
        "\n",
        "augmented_images = torch.stack(augmented_images)\n",
        "augmented_labels = torch.tensor(augmented_labels, dtype=torch.long)\n",
        "\n",
        "X_train = augmented_images\n",
        "y_train = augmented_labels\n",
        "\n",
        "train_dataset = ShapeDataset(X_train, y_train, transform=None)\n",
        "test_dataset = ShapeDataset(X_test, y_test, transform=None)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"New Training data shape: {train_dataset.shape()}\")\n",
        "print(f\"New Training data shape: {test_dataset.shape()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wTTUVRQFkmNa"
      },
      "outputs": [],
      "source": [
        "class ImprovedShapeClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedShapeClassifier, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.fc2 = nn.Linear(128, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcRLw9s7koBf",
        "outputId": "355c632a-21a0-45ca-d0f0-78d0f39379ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Loss: 0.5502523226008568\n",
            "Epoch [2/15], Loss: 0.22789788844922906\n",
            "Epoch [3/15], Loss: 0.1592528848870568\n",
            "Epoch [4/15], Loss: 0.13831854531686055\n",
            "Epoch [5/15], Loss: 0.1294964459431294\n",
            "Epoch [6/15], Loss: 0.11774667229112153\n",
            "Epoch [7/15], Loss: 0.10513983568661425\n",
            "Epoch [8/15], Loss: 0.10427386822714789\n",
            "Epoch [9/15], Loss: 0.10384256289378829\n",
            "Epoch [10/15], Loss: 0.08891717818901623\n",
            "Epoch [11/15], Loss: 0.058068999644266824\n",
            "Epoch [12/15], Loss: 0.0485492148457869\n",
            "Epoch [13/15], Loss: 0.04300375570028544\n",
            "Epoch [14/15], Loss: 0.03712638155621004\n"
          ]
        }
      ],
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = ImprovedShapeClassifier()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)  # weight_decay adds L2 regularization\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Decreases learning rate by 0.1 every 10 epochs\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(images)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "     # Step the scheduler\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'shape_classifier.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "380QhUITkrMK",
        "outputId": "60d80c33-118e-4d27-a1f6-df9a682ce2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.36666666666666%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f0YQyUIO6BPH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU_1UosWktFJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9f327c-a967-4cf3-b11f-2b071f00341f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes saved to 'predicted_classes.txt'\n"
          ]
        }
      ],
      "source": [
        "import pickle, gzip\n",
        "\n",
        "with gzip.open('/content/drive/MyDrive/Colab Notebooks/flatland_test.data', 'rb') as f:\n",
        "    X_t, y_test = pickle.load(f)\n",
        "\n",
        "X_t = X_t / 255.0\n",
        "\n",
        "X_t = X_t.reshape(-1, 1, 50, 50)\n",
        "X_t = torch.tensor(X_t, dtype=torch.float32)\n",
        "\n",
        "model.eval()\n",
        "predicted_classes = []\n",
        "batch_size = 256\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(X_t), batch_size):\n",
        "        batch_X = X_t[i:i + batch_size]\n",
        "        batch_predictions = model(batch_X)\n",
        "        batch_predicted_classes = torch.argmax(batch_predictions, dim=1).cpu().numpy()\n",
        "        predicted_classes.extend(batch_predicted_classes)\n",
        "\n",
        "\n",
        "predicted_classes = np.array(predicted_classes)\n",
        "predicted_classes[predicted_classes != 0] += 2\n",
        "\n",
        "\n",
        "result_string = ''.join(map(str, predicted_classes))\n",
        "with open('predicted_classes.txt', 'w') as f:\n",
        "    f.write(result_string)\n",
        "\n",
        "print(\"Predicted classes saved to 'predicted_classes.txt'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "q-oo1Q4FnG6Z",
        "outputId": "d1806480-47b9-4b8e-b1dd-9c1646a4d35c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aa382d35-63a8-4ccf-8e6e-501f8672f267\", \"predicted_classes.txt\", 10000)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('predicted_classes.txt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}